data:
  train_img_dir: 'dataset/full_train'
  train_mask_dir: 'dataset/full_train_annotations'
  val_img_dir: 'dataset/full_val'
  val_mask_dir: 'dataset/full_val_annotations'
  imgsz: 1024
  augment: True
  num_workers: 8
  cache: False
  aug_param:
    hsv: 0.4
    mini_mosaic: 0.7
    flip_lr: 0.3
    neg: 0.0
    size_range: [0.85, 1.1]
    rotate: 0.3
    rotate_range: [-20, 20]
  save_dir: 'results'

train:
  epochs: 80
  linear_lr: False
  optimizer: 'adam' # or 'sgd'
  batch_size: 128
  lr0: 0.01
  lrf: 0.002
  warm_up: True
  momentum: 0.937
  weight_decay: 0.00002
  warmup_epochs: 3.0  # warmup epochs (fractions ok)
  warmup_momentum: 0.8  # warmup initial momentum
  warmup_bias_lr: 0.1  # warmup initial bias lr
  eval_interval: 1
  loss: 'bce'
  accumulation_steps: 4

model:
  weights: 'data/comictextdetector-blk_det.pt'
  unet_weights: 'data/comictextdetector-text_seg.pt'
  db_weights: 'data/kuzushiji-text_det.pt'
  act: 'leaky'

logger:
  type: 'wandb'
  run_id: ''
  project: 'ComicTextDetector for Kuzushiji'

resume:
  resume_training: False
  ckpt: ''
  
